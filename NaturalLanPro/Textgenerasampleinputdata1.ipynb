{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Textgenerasampleinputdata1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeY3hWhZbxeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "dbd49cb6-2472-4014-f5c9-0239ab1026c4"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4_A9xwEbyB7",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "dfef17ae-e217-49fb-de62-22c5e69ebb28"
      },
      "source": [
        "from google.colab import files\n",
        "path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e703f7a0-c259-4c4f-a15f-883bcfe36bbf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e703f7a0-c259-4c4f-a15f-883bcfe36bbf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Untitled document.txt to Untitled document (1).txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f0cf22c78c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpath_to_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m           filename=filename, local_filename=local_filename))\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ab'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m       \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKdt0Hu0byEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16254ba8-3f2c-42c7-8b8f-135d8c48d16b"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 11107 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiE37G5sbyMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7a06f081-666c-43dd-d71a-bab75bc07729"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\"Look at this stupid dog.\" Ramesh exclaimed\r\n",
            "exasperated. \"He's scared of his own shadow.\" \r\n",
            "\"What'd he do this time?\" asked Ayesha. Ayesha and Ramesh were a happy couple who had been married for nine years. They lived in a medium-size ranch house i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCDCDOVobyPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVwkL9TPbySI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzB6Jda2byVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100  # length of sequence for a training example\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC4_O1zmbyXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eQwbNRPbyaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):  # for the example: hello\n",
        "    input_text = chunk[:-1]  # hell\n",
        "    target_text = chunk[1:]  # ello\n",
        "    return input_text, target_text  # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5SdHdeMbydQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "937c37ca-3cf4-45fb-d314-aaa6e304d651"
      },
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "﻿\"Look at this stupid dog.\" Ramesh exclaimed\r\n",
            "exasperated. \"He's scared of his own shadow.\" \r\n",
            "\"What'\n",
            "\n",
            "OUTPUT\n",
            "\"Look at this stupid dog.\" Ramesh exclaimed\r\n",
            "exasperated. \"He's scared of his own shadow.\" \r\n",
            "\"What'd\n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            " he do this time?\" asked Ayesha. Ayesha and Ramesh were a happy couple who had been married for nine\n",
            "\n",
            "OUTPUT\n",
            "he do this time?\" asked Ayesha. Ayesha and Ramesh were a happy couple who had been married for nine \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpkPwvqDc8xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj4rUPRwc873",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "dd4c7f98-c2c2-4863-8598-ba1210ed96f5"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           15360     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 60)            61500     \n",
            "=================================================================\n",
            "Total params: 5,323,836\n",
            "Trainable params: 5,323,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHmjTBYJbygB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvR9Cb8HdNmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64cbdd6b-3b55-4163-8bba-458acd5e0f3f"
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 60) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdbrehpndNo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def losts(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwjSD8MTdNrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=losts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgfwJ8uidNud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HByu0upNdNxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "988373ed-6ee0-4056-b843-b3e0439bc3f9"
      },
      "source": [
        "import time\n",
        "x = time.time()\n",
        "history = model.fit(data, epochs=5000, callbacks=[checkpoint_callback])\n",
        "answer = time.time()-x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 4.0924\n",
            "Epoch 2/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4.0365\n",
            "Epoch 3/5000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 3.8132\n",
            "Epoch 4/5000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 3.6463\n",
            "Epoch 5/5000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 3.6564\n",
            "Epoch 6/5000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 3.5710\n",
            "Epoch 7/5000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 3.3564\n",
            "Epoch 8/5000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 3.2224\n",
            "Epoch 9/5000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 3.1901\n",
            "Epoch 10/5000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 3.2491\n",
            "Epoch 11/5000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 3.1419\n",
            "Epoch 12/5000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 3.1369\n",
            "Epoch 13/5000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 3.1594\n",
            "Epoch 14/5000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 3.1472\n",
            "Epoch 15/5000\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 3.1511\n",
            "Epoch 16/5000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 3.1188\n",
            "Epoch 17/5000\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 3.1258\n",
            "Epoch 18/5000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 3.1043\n",
            "Epoch 19/5000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 3.1084\n",
            "Epoch 20/5000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 3.0950\n",
            "Epoch 21/5000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 3.1243\n",
            "Epoch 22/5000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 3.0904\n",
            "Epoch 23/5000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 3.0849\n",
            "Epoch 24/5000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 3.0738\n",
            "Epoch 25/5000\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 3.0825\n",
            "Epoch 26/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.0657\n",
            "Epoch 27/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.0568\n",
            "Epoch 28/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 3.0614\n",
            "Epoch 29/5000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 3.0526\n",
            "Epoch 30/5000\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 3.0597\n",
            "Epoch 31/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.0294\n",
            "Epoch 32/5000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 3.0412\n",
            "Epoch 33/5000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 3.0130\n",
            "Epoch 34/5000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 3.0045\n",
            "Epoch 35/5000\n",
            "1/1 [==============================] - 7s 7s/step - loss: 3.0026\n",
            "Epoch 36/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.0020\n",
            "Epoch 37/5000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.9829\n",
            "Epoch 38/5000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.9650\n",
            "Epoch 39/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 2.9618\n",
            "Epoch 40/5000\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 2.9368\n",
            "Epoch 41/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.9189\n",
            "Epoch 42/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.9106\n",
            "Epoch 43/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.8863\n",
            "Epoch 44/5000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.8825\n",
            "Epoch 45/5000\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 2.8425\n",
            "Epoch 46/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.8374\n",
            "Epoch 47/5000\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 2.8104\n",
            "Epoch 48/5000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.7735\n",
            "Epoch 49/5000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.7450\n",
            "Epoch 50/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.7111\n",
            "Epoch 51/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 2.6758\n",
            "Epoch 52/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6704\n",
            "Epoch 53/5000\n",
            "1/1 [==============================] - 1s 588ms/step - loss: 2.6243\n",
            "Epoch 54/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.6250\n",
            "Epoch 55/5000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 2.5645\n",
            "Epoch 56/5000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.5566\n",
            "Epoch 57/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.5170\n",
            "Epoch 58/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.5145\n",
            "Epoch 59/5000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.5080\n",
            "Epoch 60/5000\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 2.4573\n",
            "Epoch 61/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.4589\n",
            "Epoch 62/5000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 2.4553\n",
            "Epoch 63/5000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 2.4105\n",
            "Epoch 64/5000\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 2.4160\n",
            "Epoch 65/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3835\n",
            "Epoch 66/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.3816\n",
            "Epoch 67/5000\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 2.3595\n",
            "Epoch 68/5000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 2.3472\n",
            "Epoch 69/5000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 2.3451\n",
            "Epoch 70/5000\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 2.3348\n",
            "Epoch 71/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3387\n",
            "Epoch 72/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3148\n",
            "Epoch 73/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.2851\n",
            "Epoch 74/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2627\n",
            "Epoch 75/5000\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 2.2660\n",
            "Epoch 76/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2550\n",
            "Epoch 77/5000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.2345\n",
            "Epoch 78/5000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 2.2279\n",
            "Epoch 79/5000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 2.2136\n",
            "Epoch 80/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.1951\n",
            "Epoch 81/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.1996\n",
            "Epoch 82/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.1957\n",
            "Epoch 83/5000\n",
            "1/1 [==============================] - 1s 541ms/step - loss: 2.1698\n",
            "Epoch 84/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.1541\n",
            "Epoch 85/5000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 2.1753\n",
            "Epoch 86/5000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.1308\n",
            "Epoch 87/5000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 2.1282\n",
            "Epoch 88/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.1162\n",
            "Epoch 89/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 2.1039\n",
            "Epoch 90/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1063\n",
            "Epoch 91/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.1021\n",
            "Epoch 92/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0774\n",
            "Epoch 93/5000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 2.0894\n",
            "Epoch 94/5000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 2.0913\n",
            "Epoch 95/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 2.0727\n",
            "Epoch 96/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.0602\n",
            "Epoch 97/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.0423\n",
            "Epoch 98/5000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.0566\n",
            "Epoch 99/5000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 2.0187\n",
            "Epoch 100/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.0117\n",
            "Epoch 101/5000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.0301\n",
            "Epoch 102/5000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.0107\n",
            "Epoch 103/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0264\n",
            "Epoch 104/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 2.0286\n",
            "Epoch 105/5000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.0156\n",
            "Epoch 106/5000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 2.0055\n",
            "Epoch 107/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.9979\n",
            "Epoch 108/5000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 1.9669\n",
            "Epoch 109/5000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 1.9640\n",
            "Epoch 110/5000\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 1.9635\n",
            "Epoch 111/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.9481\n",
            "Epoch 112/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.9232\n",
            "Epoch 113/5000\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 1.9075\n",
            "Epoch 114/5000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 1.9255\n",
            "Epoch 115/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.9019\n",
            "Epoch 116/5000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.8946\n",
            "Epoch 117/5000\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 1.8739\n",
            "Epoch 118/5000\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 1.9000\n",
            "Epoch 119/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.8516\n",
            "Epoch 120/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.8455\n",
            "Epoch 121/5000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.8827\n",
            "Epoch 122/5000\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.8342\n",
            "Epoch 123/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.8341\n",
            "Epoch 124/5000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 1.7877\n",
            "Epoch 125/5000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 1.8408\n",
            "Epoch 126/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.7982\n",
            "Epoch 127/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.7866\n",
            "Epoch 128/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.7950\n",
            "Epoch 129/5000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 1.7609\n",
            "Epoch 130/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.7807\n",
            "Epoch 131/5000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 1.7675\n",
            "Epoch 132/5000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 1.7610\n",
            "Epoch 133/5000\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.7248\n",
            "Epoch 134/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.7335\n",
            "Epoch 135/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.7039\n",
            "Epoch 136/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.7370\n",
            "Epoch 137/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.6960\n",
            "Epoch 138/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.6686\n",
            "Epoch 139/5000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.6888\n",
            "Epoch 140/5000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 1.6926\n",
            "Epoch 141/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.6342\n",
            "Epoch 142/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.6508\n",
            "Epoch 143/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.6374\n",
            "Epoch 144/5000\n",
            "1/1 [==============================] - 1s 544ms/step - loss: 1.6709\n",
            "Epoch 145/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.6312\n",
            "Epoch 146/5000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 1.6440\n",
            "Epoch 147/5000\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 1.6016\n",
            "Epoch 148/5000\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 1.5925\n",
            "Epoch 149/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.6038\n",
            "Epoch 150/5000\n",
            "1/1 [==============================] - 0s 418ms/step - loss: 1.5591\n",
            "Epoch 151/5000\n",
            "1/1 [==============================] - 1s 635ms/step - loss: 1.5796\n",
            "Epoch 152/5000\n",
            "1/1 [==============================] - 1s 614ms/step - loss: 1.5516\n",
            "Epoch 153/5000\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 1.5136\n",
            "Epoch 154/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.5183\n",
            "Epoch 155/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4958\n",
            "Epoch 156/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.4520\n",
            "Epoch 157/5000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.4630\n",
            "Epoch 158/5000\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 1.4385\n",
            "Epoch 159/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.4706\n",
            "Epoch 160/5000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 1.5043\n",
            "Epoch 161/5000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 1.4946\n",
            "Epoch 162/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4216\n",
            "Epoch 163/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.4240\n",
            "Epoch 164/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.4059\n",
            "Epoch 165/5000\n",
            "1/1 [==============================] - 1s 538ms/step - loss: 1.4020\n",
            "Epoch 166/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.3845\n",
            "Epoch 167/5000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 1.3608\n",
            "Epoch 168/5000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 1.3457\n",
            "Epoch 169/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.3539\n",
            "Epoch 170/5000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.3333\n",
            "Epoch 171/5000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 1.3301\n",
            "Epoch 172/5000\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 1.2760\n",
            "Epoch 173/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.2769\n",
            "Epoch 174/5000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.2817\n",
            "Epoch 175/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.2089\n",
            "Epoch 176/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.2116\n",
            "Epoch 177/5000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 1.2273\n",
            "Epoch 178/5000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 1.1748\n",
            "Epoch 179/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.1539\n",
            "Epoch 180/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.1356\n",
            "Epoch 181/5000\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 1.1605\n",
            "Epoch 182/5000\n",
            "1/1 [==============================] - 1s 596ms/step - loss: 1.1281\n",
            "Epoch 183/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.1248\n",
            "Epoch 184/5000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 1.0701\n",
            "Epoch 185/5000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.0880\n",
            "Epoch 186/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0626\n",
            "Epoch 187/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.0490\n",
            "Epoch 188/5000\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 1.0535\n",
            "Epoch 189/5000\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 1.0182\n",
            "Epoch 190/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.0007\n",
            "Epoch 191/5000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.9679\n",
            "Epoch 192/5000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.9431\n",
            "Epoch 193/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.9273\n",
            "Epoch 194/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.8982\n",
            "Epoch 195/5000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.8894\n",
            "Epoch 196/5000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.9213\n",
            "Epoch 197/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9195\n",
            "Epoch 198/5000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.8755\n",
            "Epoch 199/5000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.8744\n",
            "Epoch 200/5000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.8433\n",
            "Epoch 201/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.8319\n",
            "Epoch 202/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7782\n",
            "Epoch 203/5000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.7521\n",
            "Epoch 204/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7668\n",
            "Epoch 205/5000\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.7435\n",
            "Epoch 206/5000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.7222\n",
            "Epoch 207/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6776\n",
            "Epoch 208/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6734\n",
            "Epoch 209/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6736\n",
            "Epoch 210/5000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.6296\n",
            "Epoch 211/5000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.6480\n",
            "Epoch 212/5000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.6305\n",
            "Epoch 213/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6113\n",
            "Epoch 214/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5907\n",
            "Epoch 215/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5855\n",
            "Epoch 216/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5600\n",
            "Epoch 217/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5429\n",
            "Epoch 218/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5269\n",
            "Epoch 219/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4910\n",
            "Epoch 220/5000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.5101\n",
            "Epoch 221/5000\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.4949\n",
            "Epoch 222/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4782\n",
            "Epoch 223/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4722\n",
            "Epoch 224/5000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.4412\n",
            "Epoch 225/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4408\n",
            "Epoch 226/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4209\n",
            "Epoch 227/5000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4252\n",
            "Epoch 228/5000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.4429\n",
            "Epoch 229/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3891\n",
            "Epoch 230/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4007\n",
            "Epoch 231/5000\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.4038\n",
            "Epoch 232/5000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3774\n",
            "Epoch 233/5000\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 0.3692\n",
            "Epoch 234/5000\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.3569\n",
            "Epoch 235/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3460\n",
            "Epoch 236/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3510\n",
            "Epoch 237/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3357\n",
            "Epoch 238/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.3362\n",
            "Epoch 239/5000\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3304\n",
            "Epoch 240/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3139\n",
            "Epoch 241/5000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3178\n",
            "Epoch 242/5000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3182\n",
            "Epoch 243/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2968\n",
            "Epoch 244/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2921\n",
            "Epoch 245/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.3016\n",
            "Epoch 246/5000\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3081\n",
            "Epoch 247/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2780\n",
            "Epoch 248/5000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.2870\n",
            "Epoch 249/5000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2784\n",
            "Epoch 250/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2709\n",
            "Epoch 251/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2776\n",
            "Epoch 252/5000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.2671\n",
            "Epoch 253/5000\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 0.2516\n",
            "Epoch 254/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2619\n",
            "Epoch 255/5000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2474\n",
            "Epoch 256/5000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.2588\n",
            "Epoch 257/5000\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.2458\n",
            "Epoch 258/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2432\n",
            "Epoch 259/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2367\n",
            "Epoch 260/5000\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.2381\n",
            "Epoch 261/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2408\n",
            "Epoch 262/5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2307\n",
            "Epoch 263/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.2319\n",
            "Epoch 264/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2233\n",
            "Epoch 265/5000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2217\n",
            "Epoch 266/5000\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.2412\n",
            "Epoch 267/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2171\n",
            "Epoch 268/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2245\n",
            "Epoch 269/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2286\n",
            "Epoch 270/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2123\n",
            "Epoch 271/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2052\n",
            "Epoch 272/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2092\n",
            "Epoch 273/5000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.2128\n",
            "Epoch 274/5000\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.2030\n",
            "Epoch 275/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2027\n",
            "Epoch 276/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1903\n",
            "Epoch 277/5000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.2020\n",
            "Epoch 278/5000\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.1936\n",
            "Epoch 279/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1973\n",
            "Epoch 280/5000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.1980\n",
            "Epoch 281/5000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.1905\n",
            "Epoch 282/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1948\n",
            "Epoch 283/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1836\n",
            "Epoch 284/5000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1763\n",
            "Epoch 285/5000\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 0.1973\n",
            "Epoch 286/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1819\n",
            "Epoch 287/5000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.1871\n",
            "Epoch 288/5000\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.1757\n",
            "Epoch 289/5000\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.1754\n",
            "Epoch 290/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1731\n",
            "Epoch 291/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1724\n",
            "Epoch 292/5000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1771\n",
            "Epoch 293/5000\n",
            "1/1 [==============================] - 1s 635ms/step - loss: 0.1721\n",
            "Epoch 294/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1646\n",
            "Epoch 295/5000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.1688\n",
            "Epoch 296/5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.1709\n",
            "Epoch 297/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1666\n",
            "Epoch 298/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1651\n",
            "Epoch 299/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1682\n",
            "Epoch 300/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1571\n",
            "Epoch 301/5000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.1685\n",
            "Epoch 302/5000\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.1634\n",
            "Epoch 303/5000\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.1644\n",
            "Epoch 304/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.1591\n",
            "Epoch 305/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1603\n",
            "Epoch 306/5000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.1544\n",
            "Epoch 307/5000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1507\n",
            "Epoch 308/5000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.1576\n",
            "Epoch 309/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1509\n",
            "Epoch 310/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1417\n",
            "Epoch 311/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1443\n",
            "Epoch 312/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1565\n",
            "Epoch 313/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1604\n",
            "Epoch 314/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1522\n",
            "Epoch 315/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1435\n",
            "Epoch 316/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1401\n",
            "Epoch 317/5000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.1361\n",
            "Epoch 318/5000\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.1453\n",
            "Epoch 319/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1365\n",
            "Epoch 320/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1528\n",
            "Epoch 321/5000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1346\n",
            "Epoch 322/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1411\n",
            "Epoch 323/5000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.1421\n",
            "Epoch 324/5000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.1357\n",
            "Epoch 325/5000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.1355\n",
            "Epoch 326/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1496\n",
            "Epoch 327/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1357\n",
            "Epoch 328/5000\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.1341\n",
            "Epoch 329/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1378\n",
            "Epoch 330/5000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.1400\n",
            "Epoch 331/5000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.1322\n",
            "Epoch 332/5000\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.1371\n",
            "Epoch 333/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279\n",
            "Epoch 334/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224\n",
            "Epoch 335/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1367\n",
            "Epoch 336/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1334\n",
            "Epoch 337/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1297\n",
            "Epoch 338/5000\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.1299\n",
            "Epoch 339/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1319\n",
            "Epoch 340/5000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.1260\n",
            "Epoch 341/5000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.1308\n",
            "Epoch 342/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1221\n",
            "Epoch 343/5000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1198\n",
            "Epoch 344/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1298\n",
            "Epoch 345/5000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1131\n",
            "Epoch 346/5000\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.1215\n",
            "Epoch 347/5000\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.1150\n",
            "Epoch 348/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149\n",
            "Epoch 349/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1205\n",
            "Epoch 350/5000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1185\n",
            "Epoch 351/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1224\n",
            "Epoch 352/5000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.1086\n",
            "Epoch 353/5000\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.1173\n",
            "Epoch 354/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1211\n",
            "Epoch 355/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109\n",
            "Epoch 356/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1173\n",
            "Epoch 357/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179\n",
            "Epoch 358/5000\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.1175\n",
            "Epoch 359/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165\n",
            "Epoch 360/5000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1100\n",
            "Epoch 361/5000\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.1168\n",
            "Epoch 362/5000\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 0.1215\n",
            "Epoch 363/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1105\n",
            "Epoch 364/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1159\n",
            "Epoch 365/5000\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 0.1151\n",
            "Epoch 366/5000\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 0.1125\n",
            "Epoch 367/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1141\n",
            "Epoch 368/5000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.1086\n",
            "Epoch 369/5000\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.1076\n",
            "Epoch 370/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1155\n",
            "Epoch 371/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1054\n",
            "Epoch 372/5000\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.0976\n",
            "Epoch 373/5000\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1124\n",
            "Epoch 374/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1097\n",
            "Epoch 375/5000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.1066\n",
            "Epoch 376/5000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0966\n",
            "Epoch 377/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1100\n",
            "Epoch 378/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1058\n",
            "Epoch 379/5000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.1069\n",
            "Epoch 380/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1071\n",
            "Epoch 381/5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1068\n",
            "Epoch 382/5000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1082\n",
            "Epoch 383/5000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0996\n",
            "Epoch 384/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1045\n",
            "Epoch 385/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1002\n",
            "Epoch 386/5000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1017\n",
            "Epoch 387/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0909\n",
            "Epoch 388/5000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0975\n",
            "Epoch 389/5000\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.0995\n",
            "Epoch 390/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1053\n",
            "Epoch 391/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943\n",
            "Epoch 392/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1001\n",
            "Epoch 393/5000\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.1023\n",
            "Epoch 394/5000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0943\n",
            "Epoch 395/5000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.1037\n",
            "Epoch 396/5000\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.0996\n",
            "Epoch 397/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974\n",
            "Epoch 398/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985\n",
            "Epoch 399/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0928\n",
            "Epoch 400/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1009\n",
            "Epoch 401/5000\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.0968\n",
            "Epoch 402/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1022\n",
            "Epoch 403/5000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0942\n",
            "Epoch 404/5000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.1019\n",
            "Epoch 405/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925\n",
            "Epoch 406/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0964\n",
            "Epoch 407/5000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0849\n",
            "Epoch 408/5000\n",
            "1/1 [==============================] - 1s 604ms/step - loss: 0.0935\n",
            "Epoch 409/5000\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0872\n",
            "Epoch 410/5000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0918\n",
            "Epoch 411/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0856\n",
            "Epoch 412/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0936\n",
            "Epoch 413/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0882\n",
            "Epoch 414/5000\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.0826\n",
            "Epoch 415/5000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0845\n",
            "Epoch 416/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917\n",
            "Epoch 417/5000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.0880\n",
            "Epoch 418/5000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 0.0850\n",
            "Epoch 419/5000\n",
            "1/1 [==============================] - 1s 544ms/step - loss: 0.0915\n",
            "Epoch 420/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0877\n",
            "Epoch 421/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0874\n",
            "Epoch 422/5000\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.0890\n",
            "Epoch 423/5000\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0772\n",
            "Epoch 424/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0869\n",
            "Epoch 425/5000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.0957\n",
            "Epoch 426/5000\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.0889\n",
            "Epoch 427/5000\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.0868\n",
            "Epoch 428/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0833\n",
            "Epoch 429/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0900\n",
            "Epoch 430/5000\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.0915\n",
            "Epoch 431/5000\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0863\n",
            "Epoch 432/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0821\n",
            "Epoch 433/5000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0874\n",
            "Epoch 434/5000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0869\n",
            "Epoch 435/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0844\n",
            "Epoch 436/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0848\n",
            "Epoch 437/5000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0854\n",
            "Epoch 438/5000\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.0873\n",
            "Epoch 439/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0823\n",
            "Epoch 440/5000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0846\n",
            "Epoch 441/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0836\n",
            "Epoch 442/5000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0797\n",
            "Epoch 443/5000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.0851\n",
            "Epoch 444/5000\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.0866\n",
            "Epoch 445/5000\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.0825\n",
            "Epoch 446/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0868\n",
            "Epoch 447/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0793\n",
            "Epoch 448/5000\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.0829\n",
            "Epoch 449/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0736\n",
            "Epoch 450/5000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0830\n",
            "Epoch 451/5000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0761\n",
            "Epoch 452/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0847\n",
            "Epoch 453/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0807\n",
            "Epoch 454/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0831\n",
            "Epoch 455/5000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0838\n",
            "Epoch 456/5000\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.0835\n",
            "Epoch 457/5000\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.0735\n",
            "Epoch 458/5000\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.0783\n",
            "Epoch 459/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0795\n",
            "Epoch 460/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0765\n",
            "Epoch 461/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0759\n",
            "Epoch 462/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0773\n",
            "Epoch 463/5000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0731\n",
            "Epoch 464/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0753\n",
            "Epoch 465/5000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.0779\n",
            "Epoch 466/5000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0689\n",
            "Epoch 467/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0724\n",
            "Epoch 468/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0781\n",
            "Epoch 469/5000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0676\n",
            "Epoch 470/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0756\n",
            "Epoch 471/5000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0817\n",
            "Epoch 472/5000\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.0687\n",
            "Epoch 473/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0752\n",
            "Epoch 474/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0796\n",
            "Epoch 475/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0709\n",
            "Epoch 476/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0737\n",
            "Epoch 477/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0742\n",
            "Epoch 478/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0785\n",
            "Epoch 479/5000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0668\n",
            "Epoch 480/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.0764\n",
            "Epoch 481/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0693\n",
            "Epoch 482/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0754\n",
            "Epoch 483/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0766\n",
            "Epoch 484/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0723\n",
            "Epoch 485/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0727\n",
            "Epoch 486/5000\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.0652\n",
            "Epoch 487/5000\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.0679\n",
            "Epoch 488/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0678\n",
            "Epoch 489/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0706\n",
            "Epoch 490/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0684\n",
            "Epoch 491/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0700\n",
            "Epoch 492/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0676\n",
            "Epoch 493/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0785\n",
            "Epoch 494/5000\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0725\n",
            "Epoch 495/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0682\n",
            "Epoch 496/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0679\n",
            "Epoch 497/5000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0715\n",
            "Epoch 498/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0673\n",
            "Epoch 499/5000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.0727\n",
            "Epoch 500/5000\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.0659\n",
            "Epoch 501/5000\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0715\n",
            "Epoch 502/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0647\n",
            "Epoch 503/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0658\n",
            "Epoch 504/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0658\n",
            "Epoch 505/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0693\n",
            "Epoch 506/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0626\n",
            "Epoch 507/5000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0649\n",
            "Epoch 508/5000\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0587\n",
            "Epoch 509/5000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.0655\n",
            "Epoch 510/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0658\n",
            "Epoch 511/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0708\n",
            "Epoch 512/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0686\n",
            "Epoch 513/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0698\n",
            "Epoch 514/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0636\n",
            "Epoch 515/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0651\n",
            "Epoch 516/5000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.0676\n",
            "Epoch 517/5000\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.0686\n",
            "Epoch 518/5000\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0636\n",
            "Epoch 519/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0673\n",
            "Epoch 520/5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0578\n",
            "Epoch 521/5000\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 0.0639\n",
            "Epoch 522/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0635\n",
            "Epoch 523/5000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0647\n",
            "Epoch 524/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0647\n",
            "Epoch 525/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0633\n",
            "Epoch 526/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0639\n",
            "Epoch 527/5000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0628\n",
            "Epoch 528/5000\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.0674\n",
            "Epoch 529/5000\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.0608\n",
            "Epoch 530/5000\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.0658\n",
            "Epoch 531/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0656\n",
            "Epoch 532/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0585\n",
            "Epoch 533/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0644\n",
            "Epoch 534/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0662\n",
            "Epoch 535/5000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0601\n",
            "Epoch 536/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0638\n",
            "Epoch 537/5000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0644\n",
            "Epoch 538/5000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0553\n",
            "Epoch 539/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0621\n",
            "Epoch 540/5000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0605\n",
            "Epoch 541/5000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.0572\n",
            "Epoch 542/5000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.0656\n",
            "Epoch 543/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0563\n",
            "Epoch 544/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0678\n",
            "Epoch 545/5000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0614\n",
            "Epoch 546/5000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0638\n",
            "Epoch 547/5000\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 0.0625\n",
            "Epoch 548/5000\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.0630\n",
            "Epoch 549/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0637\n",
            "Epoch 550/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0650\n",
            "Epoch 551/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0608\n",
            "Epoch 552/5000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0592\n",
            "Epoch 553/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0598\n",
            "Epoch 554/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0577\n",
            "Epoch 555/5000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0591\n",
            "Epoch 556/5000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0569\n",
            "Epoch 557/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0603\n",
            "Epoch 558/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0611\n",
            "Epoch 559/5000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0562\n",
            "Epoch 560/5000\n",
            "1/1 [==============================] - 1s 643ms/step - loss: 0.0619\n",
            "Epoch 561/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0554\n",
            "Epoch 562/5000\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.0550\n",
            "Epoch 563/5000\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0579\n",
            "Epoch 564/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0580\n",
            "Epoch 565/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0564\n",
            "Epoch 566/5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0555\n",
            "Epoch 567/5000\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.0581\n",
            "Epoch 568/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0628\n",
            "Epoch 569/5000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0554\n",
            "Epoch 570/5000\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.0570\n",
            "Epoch 571/5000\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0627\n",
            "Epoch 572/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0523\n",
            "Epoch 573/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.0587\n",
            "Epoch 574/5000\n",
            "1/1 [==============================] - 1s 606ms/step - loss: 0.0518\n",
            "Epoch 575/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0607\n",
            "Epoch 576/5000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.0549\n",
            "Epoch 577/5000\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 0.0528\n",
            "Epoch 578/5000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.0559\n",
            "Epoch 579/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0563\n",
            "Epoch 580/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0579\n",
            "Epoch 581/5000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0540\n",
            "Epoch 582/5000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.0534\n",
            "Epoch 583/5000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.0533\n",
            "Epoch 584/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0598\n",
            "Epoch 585/5000\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.0551\n",
            "Epoch 586/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0506\n",
            "Epoch 587/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0583\n",
            "Epoch 588/5000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 0.0548\n",
            "Epoch 589/5000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.0558\n",
            "Epoch 590/5000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0584\n",
            "Epoch 591/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0518\n",
            "Epoch 592/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0574\n",
            "Epoch 593/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0496\n",
            "Epoch 594/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0544\n",
            "Epoch 595/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0520\n",
            "Epoch 596/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0501\n",
            "Epoch 597/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0580\n",
            "Epoch 598/5000\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.0515\n",
            "Epoch 599/5000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.0556\n",
            "Epoch 600/5000\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 0.0507\n",
            "Epoch 601/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0524\n",
            "Epoch 602/5000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0537\n",
            "Epoch 603/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0525\n",
            "Epoch 604/5000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 0.0499\n",
            "Epoch 605/5000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.0474\n",
            "Epoch 606/5000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.0532\n",
            "Epoch 607/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0566\n",
            "Epoch 608/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0539\n",
            "Epoch 609/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0547\n",
            "Epoch 610/5000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0568\n",
            "Epoch 611/5000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0552\n",
            "Epoch 612/5000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0533\n",
            "Epoch 613/5000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0563\n",
            "Epoch 614/5000\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.0579\n",
            "Epoch 615/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0497\n",
            "Epoch 616/5000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0518\n",
            "Epoch 617/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0504\n",
            "Epoch 618/5000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0437"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SaveV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m         tld.op_callbacks, prefix, tensor_names, shape_and_slices, tensors)\n\u001b[0m\u001b[1;32m   1703\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-08a8ab950f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[1;32m   1165\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[1;32m   1166\u001b[0m             % (optimizer,))\n\u001b[0;32m-> 1167\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m       \u001b[0;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1187\u001b[0;31m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[1;32m   1188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1134\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         return save_v2_eager_fallback(\n\u001b[1;32m   1707\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m   1709\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1728\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1730\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1731\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: training_checkpoints/ckpt_618_temp_d4947ebc9c094537bd1565463c181444/part-00001-of-00002.data-00000-of-00001.tempstate14299358588352645272; No space left on device [Op:SaveV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWhay_LudNzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEH2upnldN2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdDMjAJTdN44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GozubfdwdN7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2xchezPbyi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9BOhjP2byl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN7LDK7ibyo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j_dBp3kbyrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lqgsnh0byug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksZGXSRHbyxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MinDCfmby0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U3PgOJPby2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXPjg1XZby51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBpDToEUby8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzRKixznby-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3FeVhsVbzBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7IxwckTbzEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUzo4a4vbzG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkNxR8SsbzJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4agNvAVTbzMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxYTzyu0bzPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVoJmtS7bzR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N88ZOOWEbzUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2uD5IT2bzXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX-hmb1rbzaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaKO3d8Obzc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSJNm0eFbzfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-Nb6E01bziZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blAmivvYbzlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIC-tMgebzn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vt0wrXBbzqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ygQmMEbztU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccBqEX_rbzv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC47Pt4tbzyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "latsftjHbz1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWQ8tLfXbz33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mOgEZNJbz6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJIJ_My3bz9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi1PdIPvbz_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqIststfb0DY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CYe1Jbrb0F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyd8W1T3b0JH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt60hixkb0L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB5wJJD6b0O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFF56sFnb0R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8sdZWbMb0UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wS3r7olb0W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIzGOVDwb0Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUbHaqvIb0c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}