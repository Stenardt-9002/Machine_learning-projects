# -*- coding: utf-8 -*-
"""NLP1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xAeLzvfVYLeuubLbmt2SgygX9YOqvvRG
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name)
)

from tensorflow.python.client import device_lib

def get_available_gpus():
    local_device_protos = device_lib.list_local_devices()
    return [x.name for x in local_device_protos if x.device_type == 'GPU']

get_available_gpus()







from tensorflow.python.client import device_lib

device_lib.list_local_devices()

#//data conversion
# bags of words




vocab = {}
word_encoding = 1 
def bag_of_words(text):
  global word_encoding

  words = text.lower().split(" ")
  bag = {}
  for word in words:
    if word in vocab:
      encoding = vocab[word]
    else:
      vocab[word] = word_encoding
      encoding = word_encoding 
      word_encoding+=1    

    if encoding in bag:
      bag[encoding] += 1

    else:
      bag[encoding] = 1

  return bag
  pass

positive_review = "I thought the movie was going to be bad but it was actually amazing"
negative_review = "I thought the movie was going to be amazing but it was actually bad"

pos_bag = bag_of_words(positive_review)
neg_bag = bag_of_words(negative_review)

print("Positive:", pos_bag)
print("Negative:", neg_bag)

vocab = {}  
word_encoding = 1
def one_hot_encoding(text):
  global word_encoding

  words = text.lower().split(" ") 
  encoding = []  

  for word in words:
    if word in vocab:
      code = vocab[word]  
      encoding.append(code) 
    else:
      vocab[word] = word_encoding
      encoding.append(word_encoding)
      word_encoding += 1
  
  return encoding

text = "this is a test to see if this test will work is is test a"
encoding = one_hot_encoding(text)
print(encoding)
print(vocab)

positive_review = "I thought the movie was going to be bad but it was actually amazing"
negative_review = "I thought the movie was going to be amazing but it was actually bad"

pos_encode = one_hot_encoding(positive_review)
neg_encode = one_hot_encoding(negative_review)

print("Positive:", pos_encode)
print("Negative:", neg_encode)
#maintain specific order



# Commented out IPython magic to ensure Python compatibility.
# movie imdb dataset
# 
# %tensorflow_version 2.x 
from keras.datasets import imdb
from keras.preprocessing import sequence 
import keras 
import tensorflow as tf 
import os 
import numpy as np 
VOCAB_SIZE = 88584 
MAXLEN = 250 
BATCH_SIZE = 64 
(train_data,train_labels) , (test_data,test_labels) = imdb.load_data(num_words = VOCAB_SIZE)

train_data = sequence.pad_sequences(train_data, MAXLEN)
test_data = sequence.pad_sequences(test_data, MAXLEN)

cd ../

ls

train_data.shape

len(train_data[1])

model = tf.keras.Sequential([
                             tf.keras.layers.Embedding(VOCAB_SIZE,32),
                             tf.keras.layers.LSTM(32),
                             tf.keras.layers.Dense(1,activation="sigmoid")
])

model.summary()

train_data.shape

model.compile(loss="binary_crossentropy",optimizer = "rmsprop",metrics = ['acc'])

history = model.fit(train_data,train_labels,epochs = 30,validation_split=0.2)



results = model.evaluate(test_data,test_labels)

test_labels.shape

test_data.shape

print(results)

word_index = imdb.get_word_index()

def encode_text(text):
  tokens = keras.preprocessing.text.text_to_word_sequence(text)
  # print(tokens)
  tokens = [word_index[word] if word in word_index else 0 for word in tokens ]
  # print(tokens)
  return sequence.pad_sequences([tokens],MAXLEN)[0]
text = "that was good movie was just amazing so amazing,nice awesome amazing"
endcoded = encode_text(text)
print(endcoded)

# word_index

#reverse dict


reverse_word_index = {value: key for (key,value) in word_index.items() }
def decode_ed(integers):
  PAD = 0
  text = ""
  for num in integers:

    if num!=PAD:
      text+=reverse_word_index[num]+" "

      pass 
  return text[:-1]



print(decode_ed(endcoded))

def predict(textitem):
  encoded_text = encode_text(textitem)
  # print(encoded_text.shape)
  pred_val = np.zeros((1,250))
  print(pred_val)

  pred_val[0] = encoded_text 
  result = model.predict(pred_val)
  print(result)
  pass


positive_review = "That movie was! really loved it and would great watch it again because it was amazingly great"
predict(positive_review)

negative_review = "that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched"
predict(negative_review)



























































































