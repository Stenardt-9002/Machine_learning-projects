{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textgensample2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrmBW8LejwU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0bb605d5-ed35-46e8-8dfb-a04e5c2e45e0"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jrQUS__jy06",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c7da1f4e-b38d-4e5b-a221-66ea51e21b26"
      },
      "source": [
        "from google.colab import files\n",
        "path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c2ca49d-a304-42cd-8944-56f8f2a78f8e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c2ca49d-a304-42cd-8944-56f8f2a78f8e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Untitled document.txt to Untitled document.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RideilwRj6QU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bf7867e-51b2-4505-c8f6-a53fe83e986f"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 11107 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXTNGHBqj6TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqh48394j6Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 50  # length of sequence for a training example\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoJAEDIMj6bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSZuJrnyj6g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):  # for the example: hello\n",
        "    input_text = chunk[:-1]  # hell\n",
        "    target_text = chunk[1:]  # ello\n",
        "    return input_text, target_text  # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAKN3EVsj6jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lnEAkr1j6mL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b4e4b6a4-882d-46e7-96e0-8484f6ba200e"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           15360     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 60)            61500     \n",
            "=================================================================\n",
            "Total params: 5,323,836\n",
            "Trainable params: 5,323,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT-m04QEj6ob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f94a017c-15c5-4c92-9b88-8117ff8be078"
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 50, 60) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w94jVwikj6q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def losts(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rmBPmLcj74c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=losts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXrSzuGcj77N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaeCD0hNj8AU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ea1ef05-3541-460c-f570-b4633291f25f"
      },
      "source": [
        "import time\n",
        "x = time.time()\n",
        "history = model.fit(data, epochs=5981, callbacks=[checkpoint_callback])\n",
        "answer = time.time()-x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 2.9923\n",
            "Epoch 2/5981\n",
            "3/3 [==============================] - 2s 557ms/step - loss: 2.9759\n",
            "Epoch 3/5981\n",
            "3/3 [==============================] - 2s 576ms/step - loss: 2.9430\n",
            "Epoch 4/5981\n",
            "3/3 [==============================] - 2s 537ms/step - loss: 2.9234\n",
            "Epoch 5/5981\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 2.8893\n",
            "Epoch 6/5981\n",
            "3/3 [==============================] - 2s 560ms/step - loss: 2.8586\n",
            "Epoch 7/5981\n",
            "3/3 [==============================] - 2s 575ms/step - loss: 2.8284\n",
            "Epoch 8/5981\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.8031\n",
            "Epoch 9/5981\n",
            "3/3 [==============================] - 2s 559ms/step - loss: 2.7588\n",
            "Epoch 10/5981\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 2.7286\n",
            "Epoch 11/5981\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 2.7006\n",
            "Epoch 12/5981\n",
            "3/3 [==============================] - 2s 557ms/step - loss: 2.6758\n",
            "Epoch 13/5981\n",
            "3/3 [==============================] - 2s 568ms/step - loss: 2.6322\n",
            "Epoch 14/5981\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 2.6057\n",
            "Epoch 15/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 2.5709\n",
            "Epoch 16/5981\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 2.5459\n",
            "Epoch 17/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 2.5070\n",
            "Epoch 18/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 2.4815\n",
            "Epoch 19/5981\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 2.4500\n",
            "Epoch 20/5981\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 2.4171\n",
            "Epoch 21/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 2.3870\n",
            "Epoch 22/5981\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 2.3622\n",
            "Epoch 23/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 2.3419\n",
            "Epoch 24/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 2.3107\n",
            "Epoch 25/5981\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 2.2939\n",
            "Epoch 26/5981\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 2.2748\n",
            "Epoch 27/5981\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 2.2535\n",
            "Epoch 28/5981\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 2.2417\n",
            "Epoch 29/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 2.2210\n",
            "Epoch 30/5981\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 2.2045\n",
            "Epoch 31/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 2.1849\n",
            "Epoch 32/5981\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 2.1763\n",
            "Epoch 33/5981\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 2.1574\n",
            "Epoch 34/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 2.1503\n",
            "Epoch 35/5981\n",
            "3/3 [==============================] - 2s 548ms/step - loss: 2.1343\n",
            "Epoch 36/5981\n",
            "3/3 [==============================] - 2s 693ms/step - loss: 2.1288\n",
            "Epoch 37/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 2.1152\n",
            "Epoch 38/5981\n",
            "3/3 [==============================] - 1s 415ms/step - loss: 2.1048\n",
            "Epoch 39/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 2.0963\n",
            "Epoch 40/5981\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 2.0772\n",
            "Epoch 41/5981\n",
            "3/3 [==============================] - 3s 941ms/step - loss: 2.0672\n",
            "Epoch 42/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 2.0612\n",
            "Epoch 43/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 2.0478\n",
            "Epoch 44/5981\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 2.0384\n",
            "Epoch 45/5981\n",
            "3/3 [==============================] - 3s 891ms/step - loss: 2.0340\n",
            "Epoch 46/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 2.0192\n",
            "Epoch 47/5981\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 2.0020\n",
            "Epoch 48/5981\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 2.0052\n",
            "Epoch 49/5981\n",
            "3/3 [==============================] - 2s 751ms/step - loss: 1.9898\n",
            "Epoch 50/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 1.9812\n",
            "Epoch 51/5981\n",
            "3/3 [==============================] - 1s 381ms/step - loss: 1.9636\n",
            "Epoch 52/5981\n",
            "3/3 [==============================] - 2s 825ms/step - loss: 1.9513\n",
            "Epoch 53/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 1.9435\n",
            "Epoch 54/5981\n",
            "3/3 [==============================] - 1s 348ms/step - loss: 1.9400\n",
            "Epoch 55/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 1.9258\n",
            "Epoch 56/5981\n",
            "3/3 [==============================] - 2s 552ms/step - loss: 1.9120\n",
            "Epoch 57/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.8880\n",
            "Epoch 58/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 1.8922\n",
            "Epoch 59/5981\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 1.8748\n",
            "Epoch 60/5981\n",
            "3/3 [==============================] - 3s 966ms/step - loss: 1.8514\n",
            "Epoch 61/5981\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 1.8502\n",
            "Epoch 62/5981\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 1.8411\n",
            "Epoch 63/5981\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.8249\n",
            "Epoch 64/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.8195\n",
            "Epoch 65/5981\n",
            "3/3 [==============================] - 2s 709ms/step - loss: 1.8104\n",
            "Epoch 66/5981\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 1.8125\n",
            "Epoch 67/5981\n",
            "3/3 [==============================] - 1s 499ms/step - loss: 1.7866\n",
            "Epoch 68/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 1.7661\n",
            "Epoch 69/5981\n",
            "3/3 [==============================] - 0s 147ms/step - loss: 1.7624\n",
            "Epoch 70/5981\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 1.7499\n",
            "Epoch 71/5981\n",
            "3/3 [==============================] - 2s 621ms/step - loss: 1.7420\n",
            "Epoch 72/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 1.7331\n",
            "Epoch 73/5981\n",
            "3/3 [==============================] - 1s 354ms/step - loss: 1.7185\n",
            "Epoch 74/5981\n",
            "3/3 [==============================] - 2s 789ms/step - loss: 1.7039\n",
            "Epoch 75/5981\n",
            "3/3 [==============================] - 1s 413ms/step - loss: 1.6969\n",
            "Epoch 76/5981\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 1.6817\n",
            "Epoch 77/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 1.6750\n",
            "Epoch 78/5981\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 1.6649\n",
            "Epoch 79/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 1.6515\n",
            "Epoch 80/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 1.6328\n",
            "Epoch 81/5981\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 1.6154\n",
            "Epoch 82/5981\n",
            "3/3 [==============================] - 3s 939ms/step - loss: 1.6016\n",
            "Epoch 83/5981\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 1.6052\n",
            "Epoch 84/5981\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 1.5757\n",
            "Epoch 85/5981\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 1.5788\n",
            "Epoch 86/5981\n",
            "3/3 [==============================] - 7s 2s/step - loss: 1.5511\n",
            "Epoch 87/5981\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 1.5402\n",
            "Epoch 88/5981\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 1.5331\n",
            "Epoch 89/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 1.5137\n",
            "Epoch 90/5981\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 1.5047\n",
            "Epoch 91/5981\n",
            "3/3 [==============================] - 2s 832ms/step - loss: 1.4800\n",
            "Epoch 92/5981\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.4713\n",
            "Epoch 93/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 1.4630\n",
            "Epoch 94/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 1.4421\n",
            "Epoch 95/5981\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 1.4339\n",
            "Epoch 96/5981\n",
            "3/3 [==============================] - 3s 950ms/step - loss: 1.4047\n",
            "Epoch 97/5981\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 1.3977\n",
            "Epoch 98/5981\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 1.3960\n",
            "Epoch 99/5981\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.3750\n",
            "Epoch 100/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.3534\n",
            "Epoch 101/5981\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 1.3263\n",
            "Epoch 102/5981\n",
            "3/3 [==============================] - 3s 1s/step - loss: 1.3191\n",
            "Epoch 103/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 1.3043\n",
            "Epoch 104/5981\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 1.2910\n",
            "Epoch 105/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 1.2763\n",
            "Epoch 106/5981\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2466\n",
            "Epoch 107/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.2476\n",
            "Epoch 108/5981\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 1.2155\n",
            "Epoch 109/5981\n",
            "3/3 [==============================] - 2s 647ms/step - loss: 1.1937\n",
            "Epoch 110/5981\n",
            "3/3 [==============================] - 1s 431ms/step - loss: 1.1950\n",
            "Epoch 111/5981\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 1.1619\n",
            "Epoch 112/5981\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 1.1472\n",
            "Epoch 113/5981\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 1.1389\n",
            "Epoch 114/5981\n",
            "3/3 [==============================] - 3s 854ms/step - loss: 1.1317\n",
            "Epoch 115/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.1039\n",
            "Epoch 116/5981\n",
            "3/3 [==============================] - 1s 454ms/step - loss: 1.0863\n",
            "Epoch 117/5981\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 1.0743\n",
            "Epoch 118/5981\n",
            "3/3 [==============================] - 2s 630ms/step - loss: 1.0490\n",
            "Epoch 119/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 1.0322\n",
            "Epoch 120/5981\n",
            "3/3 [==============================] - 1s 217ms/step - loss: 1.0141\n",
            "Epoch 121/5981\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 0.9861\n",
            "Epoch 122/5981\n",
            "3/3 [==============================] - 3s 949ms/step - loss: 0.9737\n",
            "Epoch 123/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.9543\n",
            "Epoch 124/5981\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.9356\n",
            "Epoch 125/5981\n",
            "3/3 [==============================] - 2s 533ms/step - loss: 0.9215\n",
            "Epoch 126/5981\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.9140\n",
            "Epoch 127/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.8806\n",
            "Epoch 128/5981\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.8714\n",
            "Epoch 129/5981\n",
            "3/3 [==============================] - 2s 536ms/step - loss: 0.8576\n",
            "Epoch 130/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.8266\n",
            "Epoch 131/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.8116\n",
            "Epoch 132/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.7919\n",
            "Epoch 133/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.7733\n",
            "Epoch 134/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.7745\n",
            "Epoch 135/5981\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.7394\n",
            "Epoch 136/5981\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.7374\n",
            "Epoch 137/5981\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 0.7133\n",
            "Epoch 138/5981\n",
            "3/3 [==============================] - 3s 856ms/step - loss: 0.6984\n",
            "Epoch 139/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.6734\n",
            "Epoch 140/5981\n",
            "3/3 [==============================] - 0s 164ms/step - loss: 0.6649\n",
            "Epoch 141/5981\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.6533\n",
            "Epoch 142/5981\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.6428\n",
            "Epoch 143/5981\n",
            "3/3 [==============================] - 1s 306ms/step - loss: 0.6247\n",
            "Epoch 144/5981\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 0.6039\n",
            "Epoch 145/5981\n",
            "3/3 [==============================] - 3s 925ms/step - loss: 0.6012\n",
            "Epoch 146/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5900\n",
            "Epoch 147/5981\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.5801\n",
            "Epoch 148/5981\n",
            "3/3 [==============================] - 3s 935ms/step - loss: 0.5641\n",
            "Epoch 149/5981\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.5531\n",
            "Epoch 150/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.5327\n",
            "Epoch 151/5981\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.5262\n",
            "Epoch 152/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5058\n",
            "Epoch 153/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.5001\n",
            "Epoch 154/5981\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.4951\n",
            "Epoch 155/5981\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 0.4847\n",
            "Epoch 156/5981\n",
            "3/3 [==============================] - 2s 675ms/step - loss: 0.4766\n",
            "Epoch 157/5981\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.4630\n",
            "Epoch 158/5981\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 0.4469\n",
            "Epoch 159/5981\n",
            "3/3 [==============================] - 2s 578ms/step - loss: 0.4409\n",
            "Epoch 160/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4473\n",
            "Epoch 161/5981\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.4341\n",
            "Epoch 162/5981\n",
            "3/3 [==============================] - 1s 310ms/step - loss: 0.4257\n",
            "Epoch 163/5981\n",
            "3/3 [==============================] - 3s 875ms/step - loss: 0.4195\n",
            "Epoch 164/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.4136\n",
            "Epoch 165/5981\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.4116\n",
            "Epoch 166/5981\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.3963\n",
            "Epoch 167/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3860\n",
            "Epoch 168/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.3855\n",
            "Epoch 169/5981\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3813\n",
            "Epoch 170/5981\n",
            "3/3 [==============================] - 3s 863ms/step - loss: 0.3780\n",
            "Epoch 171/5981\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.3795\n",
            "Epoch 172/5981\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 0.3654\n",
            "Epoch 173/5981\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 0.3563\n",
            "Epoch 174/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.3449\n",
            "Epoch 175/5981\n",
            "3/3 [==============================] - 2s 503ms/step - loss: 0.3484\n",
            "Epoch 176/5981\n",
            "3/3 [==============================] - 2s 686ms/step - loss: 0.3457\n",
            "Epoch 177/5981\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.3458\n",
            "Epoch 178/5981\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.3432\n",
            "Epoch 179/5981\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.3305\n",
            "Epoch 180/5981\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.3338\n",
            "Epoch 181/5981\n",
            "3/3 [==============================] - 2s 743ms/step - loss: 0.3149\n",
            "Epoch 182/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.3201\n",
            "Epoch 183/5981\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 0.3147\n",
            "Epoch 184/5981\n",
            "3/3 [==============================] - 2s 766ms/step - loss: 0.3049\n",
            "Epoch 185/5981\n",
            "3/3 [==============================] - 1s 423ms/step - loss: 0.3026\n",
            "Epoch 186/5981\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.3027\n",
            "Epoch 187/5981\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.2955\n",
            "Epoch 188/5981\n",
            "3/3 [==============================] - 2s 568ms/step - loss: 0.3021\n",
            "Epoch 189/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.2901\n",
            "Epoch 190/5981\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.2875\n",
            "Epoch 191/5981\n",
            "3/3 [==============================] - 1s 365ms/step - loss: 0.2878\n",
            "Epoch 192/5981\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.2802\n",
            "Epoch 193/5981\n",
            "3/3 [==============================] - 0s 150ms/step - loss: 0.2795\n",
            "Epoch 194/5981\n",
            "3/3 [==============================] - 0s 117ms/step - loss: 0.2742\n",
            "Epoch 195/5981\n",
            "3/3 [==============================] - 2s 652ms/step - loss: 0.2766\n",
            "Epoch 196/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.2750\n",
            "Epoch 197/5981\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.2697\n",
            "Epoch 198/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.2738\n",
            "Epoch 199/5981\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.2626\n",
            "Epoch 200/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.2640\n",
            "Epoch 201/5981\n",
            "3/3 [==============================] - 2s 680ms/step - loss: 0.2693\n",
            "Epoch 202/5981\n",
            "3/3 [==============================] - 2s 633ms/step - loss: 0.2617\n",
            "Epoch 203/5981\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.2539\n",
            "Epoch 204/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.2597\n",
            "Epoch 205/5981\n",
            "3/3 [==============================] - 1s 212ms/step - loss: 0.2489\n",
            "Epoch 206/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.2574\n",
            "Epoch 207/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.2436\n",
            "Epoch 208/5981\n",
            "3/3 [==============================] - 0s 137ms/step - loss: 0.2498\n",
            "Epoch 209/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.2422\n",
            "Epoch 210/5981\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.2499\n",
            "Epoch 211/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.2326\n",
            "Epoch 212/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.2315\n",
            "Epoch 213/5981\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.2314\n",
            "Epoch 214/5981\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.2300\n",
            "Epoch 215/5981\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 0.2387\n",
            "Epoch 216/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.2308\n",
            "Epoch 217/5981\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.2334\n",
            "Epoch 218/5981\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.2296\n",
            "Epoch 219/5981\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.2288\n",
            "Epoch 220/5981\n",
            "3/3 [==============================] - 2s 662ms/step - loss: 0.2234\n",
            "Epoch 221/5981\n",
            "3/3 [==============================] - 1s 483ms/step - loss: 0.2209\n",
            "Epoch 222/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.2231\n",
            "Epoch 223/5981\n",
            "3/3 [==============================] - 1s 223ms/step - loss: 0.2167\n",
            "Epoch 224/5981\n",
            "3/3 [==============================] - 0s 136ms/step - loss: 0.2240\n",
            "Epoch 225/5981\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.2208\n",
            "Epoch 226/5981\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 0.2188\n",
            "Epoch 227/5981\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 0.2166\n",
            "Epoch 228/5981\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.2164\n",
            "Epoch 229/5981\n",
            "3/3 [==============================] - 2s 698ms/step - loss: 0.2060\n",
            "Epoch 230/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.2112\n",
            "Epoch 231/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.2107\n",
            "Epoch 232/5981\n",
            "3/3 [==============================] - 1s 206ms/step - loss: 0.2059\n",
            "Epoch 233/5981\n",
            "3/3 [==============================] - 3s 961ms/step - loss: 0.2088\n",
            "Epoch 234/5981\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.2003\n",
            "Epoch 235/5981\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 0.2087\n",
            "Epoch 236/5981\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.1950\n",
            "Epoch 237/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.2001\n",
            "Epoch 238/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.2027\n",
            "Epoch 239/5981\n",
            "3/3 [==============================] - 3s 996ms/step - loss: 0.1997\n",
            "Epoch 240/5981\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.1955\n",
            "Epoch 241/5981\n",
            "3/3 [==============================] - 1s 202ms/step - loss: 0.1948\n",
            "Epoch 242/5981\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 0.2001\n",
            "Epoch 243/5981\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 0.1948\n",
            "Epoch 244/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1960\n",
            "Epoch 245/5981\n",
            "3/3 [==============================] - 1s 389ms/step - loss: 0.1921\n",
            "Epoch 246/5981\n",
            "3/3 [==============================] - 2s 749ms/step - loss: 0.1859\n",
            "Epoch 247/5981\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.1947\n",
            "Epoch 248/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.1863\n",
            "Epoch 249/5981\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 0.1871\n",
            "Epoch 250/5981\n",
            "3/3 [==============================] - 2s 732ms/step - loss: 0.1856\n",
            "Epoch 251/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1842\n",
            "Epoch 252/5981\n",
            "3/3 [==============================] - 2s 510ms/step - loss: 0.1914\n",
            "Epoch 253/5981\n",
            "3/3 [==============================] - 2s 794ms/step - loss: 0.1854\n",
            "Epoch 254/5981\n",
            "3/3 [==============================] - 1s 405ms/step - loss: 0.1828\n",
            "Epoch 255/5981\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.1805\n",
            "Epoch 256/5981\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 0.1749\n",
            "Epoch 257/5981\n",
            "3/3 [==============================] - 1s 434ms/step - loss: 0.1838\n",
            "Epoch 258/5981\n",
            "3/3 [==============================] - 2s 551ms/step - loss: 0.1789\n",
            "Epoch 259/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1831\n",
            "Epoch 260/5981\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 0.1782\n",
            "Epoch 261/5981\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.1742\n",
            "Epoch 262/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1770\n",
            "Epoch 263/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.1710\n",
            "Epoch 264/5981\n",
            "3/3 [==============================] - 2s 564ms/step - loss: 0.1796\n",
            "Epoch 265/5981\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.1852\n",
            "Epoch 266/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.1719\n",
            "Epoch 267/5981\n",
            "3/3 [==============================] - 1s 465ms/step - loss: 0.1678\n",
            "Epoch 268/5981\n",
            "3/3 [==============================] - 1s 451ms/step - loss: 0.1705\n",
            "Epoch 269/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1681\n",
            "Epoch 270/5981\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.1713\n",
            "Epoch 271/5981\n",
            "3/3 [==============================] - 1s 434ms/step - loss: 0.1667\n",
            "Epoch 272/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.1647\n",
            "Epoch 273/5981\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 0.1568\n",
            "Epoch 274/5981\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.1614\n",
            "Epoch 275/5981\n",
            "3/3 [==============================] - 2s 831ms/step - loss: 0.1623\n",
            "Epoch 276/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1618\n",
            "Epoch 277/5981\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 0.1592\n",
            "Epoch 278/5981\n",
            "3/3 [==============================] - 1s 398ms/step - loss: 0.1604\n",
            "Epoch 279/5981\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 0.1588\n",
            "Epoch 280/5981\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 0.1570\n",
            "Epoch 281/5981\n",
            "3/3 [==============================] - 2s 633ms/step - loss: 0.1605\n",
            "Epoch 282/5981\n",
            "3/3 [==============================] - 2s 697ms/step - loss: 0.1610\n",
            "Epoch 283/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1607\n",
            "Epoch 284/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1528\n",
            "Epoch 285/5981\n",
            "3/3 [==============================] - 1s 187ms/step - loss: 0.1637\n",
            "Epoch 286/5981\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.1573\n",
            "Epoch 287/5981\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 0.1531\n",
            "Epoch 288/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1546\n",
            "Epoch 289/5981\n",
            "3/3 [==============================] - 1s 208ms/step - loss: 0.1518\n",
            "Epoch 290/5981\n",
            "3/3 [==============================] - 2s 635ms/step - loss: 0.1580\n",
            "Epoch 291/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1523\n",
            "Epoch 292/5981\n",
            "3/3 [==============================] - 2s 508ms/step - loss: 0.1550\n",
            "Epoch 293/5981\n",
            "3/3 [==============================] - 3s 953ms/step - loss: 0.1508\n",
            "Epoch 294/5981\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.1526\n",
            "Epoch 295/5981\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.1516\n",
            "Epoch 296/5981\n",
            "3/3 [==============================] - 0s 120ms/step - loss: 0.1495\n",
            "Epoch 297/5981\n",
            "3/3 [==============================] - 2s 712ms/step - loss: 0.1446\n",
            "Epoch 298/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1420\n",
            "Epoch 299/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1462\n",
            "Epoch 300/5981\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.1445\n",
            "Epoch 301/5981\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.1443\n",
            "Epoch 302/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.1491\n",
            "Epoch 303/5981\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.1425\n",
            "Epoch 304/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1473\n",
            "Epoch 305/5981\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 0.1451\n",
            "Epoch 306/5981\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 0.1465\n",
            "Epoch 307/5981\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.1378\n",
            "Epoch 308/5981\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.1453\n",
            "Epoch 309/5981\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.1491\n",
            "Epoch 310/5981\n",
            "3/3 [==============================] - 2s 618ms/step - loss: 0.1384\n",
            "Epoch 311/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1416\n",
            "Epoch 312/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.1392\n",
            "Epoch 313/5981\n",
            "3/3 [==============================] - 3s 926ms/step - loss: 0.1392\n",
            "Epoch 314/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1380\n",
            "Epoch 315/5981\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.1400\n",
            "Epoch 316/5981\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 0.1406\n",
            "Epoch 317/5981\n",
            "3/3 [==============================] - 1s 207ms/step - loss: 0.1435\n",
            "Epoch 318/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.1391\n",
            "Epoch 319/5981\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.1414\n",
            "Epoch 320/5981\n",
            "3/3 [==============================] - 1s 199ms/step - loss: 0.1365\n",
            "Epoch 321/5981\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.1337\n",
            "Epoch 322/5981\n",
            "3/3 [==============================] - 1s 384ms/step - loss: 0.1327\n",
            "Epoch 323/5981\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.1386\n",
            "Epoch 324/5981\n",
            "3/3 [==============================] - 2s 704ms/step - loss: 0.1382\n",
            "Epoch 325/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1324\n",
            "Epoch 326/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1368\n",
            "Epoch 327/5981\n",
            "3/3 [==============================] - 1s 196ms/step - loss: 0.1322\n",
            "Epoch 328/5981\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.1303\n",
            "Epoch 329/5981\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.1324\n",
            "Epoch 330/5981\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.1314\n",
            "Epoch 331/5981\n",
            "3/3 [==============================] - 1s 439ms/step - loss: 0.1317\n",
            "Epoch 332/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1359\n",
            "Epoch 333/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1313\n",
            "Epoch 334/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1362\n",
            "Epoch 335/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1295\n",
            "Epoch 336/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.1297\n",
            "Epoch 337/5981\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.1274\n",
            "Epoch 338/5981\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 0.1286\n",
            "Epoch 339/5981\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.1266\n",
            "Epoch 340/5981\n",
            "3/3 [==============================] - 2s 712ms/step - loss: 0.1296\n",
            "Epoch 341/5981\n",
            "3/3 [==============================] - 2s 556ms/step - loss: 0.1299\n",
            "Epoch 342/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1258\n",
            "Epoch 343/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1322\n",
            "Epoch 344/5981\n",
            "3/3 [==============================] - 1s 205ms/step - loss: 0.1266\n",
            "Epoch 345/5981\n",
            "3/3 [==============================] - 3s 946ms/step - loss: 0.1258\n",
            "Epoch 346/5981\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.1246\n",
            "Epoch 347/5981\n",
            "3/3 [==============================] - 0s 133ms/step - loss: 0.1204\n",
            "Epoch 348/5981\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 0.1288\n",
            "Epoch 349/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.1267\n",
            "Epoch 350/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.1269\n",
            "Epoch 351/5981\n",
            "3/3 [==============================] - 1s 188ms/step - loss: 0.1201\n",
            "Epoch 352/5981\n",
            "3/3 [==============================] - 3s 908ms/step - loss: 0.1257\n",
            "Epoch 353/5981\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.1206\n",
            "Epoch 354/5981\n",
            "3/3 [==============================] - 1s 186ms/step - loss: 0.1214\n",
            "Epoch 355/5981\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 0.1214\n",
            "Epoch 356/5981\n",
            "3/3 [==============================] - 2s 782ms/step - loss: 0.1164\n",
            "Epoch 357/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1266\n",
            "Epoch 358/5981\n",
            "3/3 [==============================] - 1s 422ms/step - loss: 0.1202\n",
            "Epoch 359/5981\n",
            "3/3 [==============================] - 2s 788ms/step - loss: 0.1232\n",
            "Epoch 360/5981\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 0.1206\n",
            "Epoch 361/5981\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.1209\n",
            "Epoch 362/5981\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.1176\n",
            "Epoch 363/5981\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.1206\n",
            "Epoch 364/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1195\n",
            "Epoch 365/5981\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.1141\n",
            "Epoch 366/5981\n",
            "3/3 [==============================] - 2s 786ms/step - loss: 0.1196\n",
            "Epoch 367/5981\n",
            "3/3 [==============================] - 1s 409ms/step - loss: 0.1211\n",
            "Epoch 368/5981\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.1211\n",
            "Epoch 369/5981\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 0.1187\n",
            "Epoch 370/5981\n",
            "3/3 [==============================] - 2s 583ms/step - loss: 0.1127\n",
            "Epoch 371/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1171\n",
            "Epoch 372/5981\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.1158\n",
            "Epoch 373/5981\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.1205\n",
            "Epoch 374/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1166\n",
            "Epoch 375/5981\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.1112\n",
            "Epoch 376/5981\n",
            "3/3 [==============================] - 2s 833ms/step - loss: 0.1100\n",
            "Epoch 377/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.1206\n",
            "Epoch 378/5981\n",
            "3/3 [==============================] - 1s 437ms/step - loss: 0.1167\n",
            "Epoch 379/5981\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.1117\n",
            "Epoch 380/5981\n",
            "3/3 [==============================] - 1s 476ms/step - loss: 0.1191\n",
            "Epoch 381/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1093\n",
            "Epoch 382/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.1149\n",
            "Epoch 383/5981\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.1092\n",
            "Epoch 384/5981\n",
            "3/3 [==============================] - 3s 910ms/step - loss: 0.1093\n",
            "Epoch 385/5981\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.1103\n",
            "Epoch 386/5981\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.1104\n",
            "Epoch 387/5981\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 0.1083\n",
            "Epoch 388/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.1114\n",
            "Epoch 389/5981\n",
            "3/3 [==============================] - 1s 429ms/step - loss: 0.1082\n",
            "Epoch 390/5981\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.1115\n",
            "Epoch 391/5981\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.1005\n",
            "Epoch 392/5981\n",
            "3/3 [==============================] - 1s 201ms/step - loss: 0.1085\n",
            "Epoch 393/5981\n",
            "3/3 [==============================] - 2s 513ms/step - loss: 0.1081\n",
            "Epoch 394/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1082\n",
            "Epoch 395/5981\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 0.1142\n",
            "Epoch 396/5981\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.1098\n",
            "Epoch 397/5981\n",
            "3/3 [==============================] - 2s 620ms/step - loss: 0.1095\n",
            "Epoch 398/5981\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 0.1033\n",
            "Epoch 399/5981\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.1124\n",
            "Epoch 400/5981\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 0.1101\n",
            "Epoch 401/5981\n",
            "3/3 [==============================] - 2s 704ms/step - loss: 0.1048\n",
            "Epoch 402/5981\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.1071\n",
            "Epoch 403/5981\n",
            "3/3 [==============================] - 3s 899ms/step - loss: 0.1082\n",
            "Epoch 404/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1083\n",
            "Epoch 405/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.1069\n",
            "Epoch 406/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.1021\n",
            "Epoch 407/5981\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.1064\n",
            "Epoch 408/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1028\n",
            "Epoch 409/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1074\n",
            "Epoch 410/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.1042\n",
            "Epoch 411/5981\n",
            "3/3 [==============================] - 0s 153ms/step - loss: 0.1044\n",
            "Epoch 412/5981\n",
            "3/3 [==============================] - 2s 651ms/step - loss: 0.1042\n",
            "Epoch 413/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1040\n",
            "Epoch 414/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.1037\n",
            "Epoch 415/5981\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.1014\n",
            "Epoch 416/5981\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 0.1101\n",
            "Epoch 417/5981\n",
            "3/3 [==============================] - 0s 145ms/step - loss: 0.0982\n",
            "Epoch 418/5981\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 0.1050\n",
            "Epoch 419/5981\n",
            "3/3 [==============================] - 2s 661ms/step - loss: 0.1035\n",
            "Epoch 420/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1007\n",
            "Epoch 421/5981\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.1013\n",
            "Epoch 422/5981\n",
            "3/3 [==============================] - 1s 493ms/step - loss: 0.0992\n",
            "Epoch 423/5981\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.1047\n",
            "Epoch 424/5981\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 0.1034\n",
            "Epoch 425/5981\n",
            "3/3 [==============================] - 2s 708ms/step - loss: 0.1008\n",
            "Epoch 426/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0956\n",
            "Epoch 427/5981\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.1033\n",
            "Epoch 428/5981\n",
            "3/3 [==============================] - 2s 738ms/step - loss: 0.1012\n",
            "Epoch 429/5981\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 0.0978\n",
            "Epoch 430/5981\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.1014\n",
            "Epoch 431/5981\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 0.0950\n",
            "Epoch 432/5981\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.0961\n",
            "Epoch 433/5981\n",
            "3/3 [==============================] - 2s 775ms/step - loss: 0.1041\n",
            "Epoch 434/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0978\n",
            "Epoch 435/5981\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0990\n",
            "Epoch 436/5981\n",
            "3/3 [==============================] - 0s 163ms/step - loss: 0.0954\n",
            "Epoch 437/5981\n",
            "3/3 [==============================] - 3s 863ms/step - loss: 0.0963\n",
            "Epoch 438/5981\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0967\n",
            "Epoch 439/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.0963\n",
            "Epoch 440/5981\n",
            "3/3 [==============================] - 2s 695ms/step - loss: 0.1000\n",
            "Epoch 441/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0983\n",
            "Epoch 442/5981\n",
            "3/3 [==============================] - 1s 396ms/step - loss: 0.1013\n",
            "Epoch 443/5981\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.0989\n",
            "Epoch 444/5981\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.0955\n",
            "Epoch 445/5981\n",
            "3/3 [==============================] - 1s 401ms/step - loss: 0.0980\n",
            "Epoch 446/5981\n",
            "3/3 [==============================] - 1s 462ms/step - loss: 0.0919\n",
            "Epoch 447/5981\n",
            "3/3 [==============================] - 2s 511ms/step - loss: 0.0964\n",
            "Epoch 448/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0995\n",
            "Epoch 449/5981\n",
            "3/3 [==============================] - 1s 355ms/step - loss: 0.0998\n",
            "Epoch 450/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.0932\n",
            "Epoch 451/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.0949\n",
            "Epoch 452/5981\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.0923\n",
            "Epoch 453/5981\n",
            "3/3 [==============================] - 2s 555ms/step - loss: 0.0952\n",
            "Epoch 454/5981\n",
            "3/3 [==============================] - 2s 623ms/step - loss: 0.0977\n",
            "Epoch 455/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0941\n",
            "Epoch 456/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0951\n",
            "Epoch 457/5981\n",
            "3/3 [==============================] - 1s 419ms/step - loss: 0.1015\n",
            "Epoch 458/5981\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.0948\n",
            "Epoch 459/5981\n",
            "3/3 [==============================] - 0s 146ms/step - loss: 0.1003\n",
            "Epoch 460/5981\n",
            "3/3 [==============================] - 1s 499ms/step - loss: 0.0935\n",
            "Epoch 461/5981\n",
            "3/3 [==============================] - 2s 669ms/step - loss: 0.0941\n",
            "Epoch 462/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0975\n",
            "Epoch 463/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.0897\n",
            "Epoch 464/5981\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.0977\n",
            "Epoch 465/5981\n",
            "3/3 [==============================] - 2s 774ms/step - loss: 0.0941\n",
            "Epoch 466/5981\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 0.0893\n",
            "Epoch 467/5981\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 0.0940\n",
            "Epoch 468/5981\n",
            "3/3 [==============================] - 2s 685ms/step - loss: 0.0940\n",
            "Epoch 469/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0946\n",
            "Epoch 470/5981\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.0946\n",
            "Epoch 471/5981\n",
            "3/3 [==============================] - 1s 194ms/step - loss: 0.0918\n",
            "Epoch 472/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0941\n",
            "Epoch 473/5981\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.0943\n",
            "Epoch 474/5981\n",
            "3/3 [==============================] - 3s 972ms/step - loss: 0.0878\n",
            "Epoch 475/5981\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.0960\n",
            "Epoch 476/5981\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0903\n",
            "Epoch 477/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.0928\n",
            "Epoch 478/5981\n",
            "3/3 [==============================] - 1s 496ms/step - loss: 0.0914\n",
            "Epoch 479/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0880\n",
            "Epoch 480/5981\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.0950\n",
            "Epoch 481/5981\n",
            "3/3 [==============================] - 1s 422ms/step - loss: 0.0931\n",
            "Epoch 482/5981\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.0879\n",
            "Epoch 483/5981\n",
            "3/3 [==============================] - 1s 360ms/step - loss: 0.0902\n",
            "Epoch 484/5981\n",
            "3/3 [==============================] - 0s 164ms/step - loss: 0.0926\n",
            "Epoch 485/5981\n",
            "3/3 [==============================] - 3s 863ms/step - loss: 0.0935\n",
            "Epoch 486/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0841\n",
            "Epoch 487/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0923\n",
            "Epoch 488/5981\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.0903\n",
            "Epoch 489/5981\n",
            "3/3 [==============================] - 1s 201ms/step - loss: 0.0889\n",
            "Epoch 490/5981\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.0871\n",
            "Epoch 491/5981\n",
            "3/3 [==============================] - 2s 635ms/step - loss: 0.0858\n",
            "Epoch 492/5981\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.0928\n",
            "Epoch 493/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0912\n",
            "Epoch 494/5981\n",
            "3/3 [==============================] - 1s 421ms/step - loss: 0.0894\n",
            "Epoch 495/5981\n",
            "3/3 [==============================] - 2s 686ms/step - loss: 0.0898\n",
            "Epoch 496/5981\n",
            "3/3 [==============================] - 1s 427ms/step - loss: 0.0926\n",
            "Epoch 497/5981\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.0904\n",
            "Epoch 498/5981\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.0831\n",
            "Epoch 499/5981\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.0908\n",
            "Epoch 500/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0924\n",
            "Epoch 501/5981\n",
            "3/3 [==============================] - 1s 474ms/step - loss: 0.0885\n",
            "Epoch 502/5981\n",
            "3/3 [==============================] - 2s 764ms/step - loss: 0.0881\n",
            "Epoch 503/5981\n",
            "3/3 [==============================] - 1s 358ms/step - loss: 0.0903\n",
            "Epoch 504/5981\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.0867\n",
            "Epoch 505/5981\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.0860\n",
            "Epoch 506/5981\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.0890\n",
            "Epoch 507/5981\n",
            "3/3 [==============================] - 2s 728ms/step - loss: 0.0914\n",
            "Epoch 508/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0868\n",
            "Epoch 509/5981\n",
            "3/3 [==============================] - 2s 701ms/step - loss: 0.0909\n",
            "Epoch 510/5981\n",
            "3/3 [==============================] - 2s 557ms/step - loss: 0.0846\n",
            "Epoch 511/5981\n",
            "3/3 [==============================] - 2s 514ms/step - loss: 0.0877\n",
            "Epoch 512/5981\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.0876\n",
            "Epoch 513/5981\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 0.0837\n",
            "Epoch 514/5981\n",
            "3/3 [==============================] - 1s 449ms/step - loss: 0.0902\n",
            "Epoch 515/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0829\n",
            "Epoch 516/5981\n",
            "3/3 [==============================] - 1s 440ms/step - loss: 0.0860\n",
            "Epoch 517/5981\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 0.0851\n",
            "Epoch 518/5981\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.0832\n",
            "Epoch 519/5981\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.0853\n",
            "Epoch 520/5981\n",
            "3/3 [==============================] - 2s 532ms/step - loss: 0.0866\n",
            "Epoch 521/5981\n",
            "3/3 [==============================] - 1s 469ms/step - loss: 0.0848\n",
            "Epoch 522/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0834\n",
            "Epoch 523/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0844\n",
            "Epoch 524/5981\n",
            "3/3 [==============================] - 1s 418ms/step - loss: 0.0875\n",
            "Epoch 525/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0918\n",
            "Epoch 526/5981\n",
            "3/3 [==============================] - 1s 190ms/step - loss: 0.0830\n",
            "Epoch 527/5981\n",
            "3/3 [==============================] - 2s 590ms/step - loss: 0.0792\n",
            "Epoch 528/5981\n",
            "3/3 [==============================] - 2s 640ms/step - loss: 0.0878\n",
            "Epoch 529/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0869\n",
            "Epoch 530/5981\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.0874\n",
            "Epoch 531/5981\n",
            "3/3 [==============================] - 1s 422ms/step - loss: 0.0869\n",
            "Epoch 532/5981\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.0865\n",
            "Epoch 533/5981\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0874\n",
            "Epoch 534/5981\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 0.0865\n",
            "Epoch 535/5981\n",
            "3/3 [==============================] - 3s 963ms/step - loss: 0.0874\n",
            "Epoch 536/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0846\n",
            "Epoch 537/5981\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 0.0831\n",
            "Epoch 538/5981\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 0.0843\n",
            "Epoch 539/5981\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 0.0867\n",
            "Epoch 540/5981\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.0830\n",
            "Epoch 541/5981\n",
            "3/3 [==============================] - 2s 551ms/step - loss: 0.0852\n",
            "Epoch 542/5981\n",
            "3/3 [==============================] - 2s 617ms/step - loss: 0.0882\n",
            "Epoch 543/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0815\n",
            "Epoch 544/5981\n",
            "3/3 [==============================] - 1s 486ms/step - loss: 0.0830\n",
            "Epoch 545/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0830\n",
            "Epoch 546/5981\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0834\n",
            "Epoch 547/5981\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.0825\n",
            "Epoch 548/5981\n",
            "3/3 [==============================] - 3s 893ms/step - loss: 0.0817\n",
            "Epoch 549/5981\n",
            "3/3 [==============================] - 1s 466ms/step - loss: 0.0842\n",
            "Epoch 550/5981\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0835\n",
            "Epoch 551/5981\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.0832\n",
            "Epoch 552/5981\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.0815\n",
            "Epoch 553/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0856\n",
            "Epoch 554/5981\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.0833\n",
            "Epoch 555/5981\n",
            "3/3 [==============================] - 3s 946ms/step - loss: 0.0832\n",
            "Epoch 556/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0867\n",
            "Epoch 557/5981\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.0840\n",
            "Epoch 558/5981\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.0793\n",
            "Epoch 559/5981\n",
            "3/3 [==============================] - 2s 548ms/step - loss: 0.0850\n",
            "Epoch 560/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0825\n",
            "Epoch 561/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.0840\n",
            "Epoch 562/5981\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.0835\n",
            "Epoch 563/5981\n",
            "3/3 [==============================] - 1s 205ms/step - loss: 0.0863\n",
            "Epoch 564/5981\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.0809\n",
            "Epoch 565/5981\n",
            "3/3 [==============================] - 2s 793ms/step - loss: 0.0827\n",
            "Epoch 566/5981\n",
            "3/3 [==============================] - 2s 547ms/step - loss: 0.0796\n",
            "Epoch 567/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0821\n",
            "Epoch 568/5981\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.0853\n",
            "Epoch 569/5981\n",
            "3/3 [==============================] - 1s 413ms/step - loss: 0.0789\n",
            "Epoch 570/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.0808\n",
            "Epoch 571/5981\n",
            "3/3 [==============================] - 1s 384ms/step - loss: 0.0826\n",
            "Epoch 572/5981\n",
            "3/3 [==============================] - 1s 450ms/step - loss: 0.0818\n",
            "Epoch 573/5981\n",
            "3/3 [==============================] - 1s 416ms/step - loss: 0.0817\n",
            "Epoch 574/5981\n",
            "3/3 [==============================] - 1s 464ms/step - loss: 0.0800\n",
            "Epoch 575/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0842\n",
            "Epoch 576/5981\n",
            "3/3 [==============================] - 1s 457ms/step - loss: 0.0815\n",
            "Epoch 577/5981\n",
            "3/3 [==============================] - 3s 896ms/step - loss: 0.0790\n",
            "Epoch 578/5981\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.0818\n",
            "Epoch 579/5981\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 0.0748\n",
            "Epoch 580/5981\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 0.0778\n",
            "Epoch 581/5981\n",
            "3/3 [==============================] - 2s 541ms/step - loss: 0.0821\n",
            "Epoch 582/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0830\n",
            "Epoch 583/5981\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.0789\n",
            "Epoch 584/5981\n",
            "3/3 [==============================] - 2s 560ms/step - loss: 0.0786\n",
            "Epoch 585/5981\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.0802\n",
            "Epoch 586/5981\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 0.0831\n",
            "Epoch 587/5981\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.0792\n",
            "Epoch 588/5981\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0823\n",
            "Epoch 589/5981\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.0780\n",
            "Epoch 590/5981\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.0834\n",
            "Epoch 591/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0777\n",
            "Epoch 592/5981\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.0785\n",
            "Epoch 593/5981\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0776\n",
            "Epoch 594/5981\n",
            "3/3 [==============================] - 2s 687ms/step - loss: 0.0785\n",
            "Epoch 595/5981\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.0765\n",
            "Epoch 596/5981\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.0811\n",
            "Epoch 597/5981\n",
            "3/3 [==============================] - 1s 217ms/step - loss: 0.0780\n",
            "Epoch 598/5981\n",
            "3/3 [==============================] - 2s 641ms/step - loss: 0.0786\n",
            "Epoch 599/5981\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0825\n",
            "Epoch 600/5981\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.0776\n",
            "Epoch 601/5981\n",
            "3/3 [==============================] - 1s 412ms/step - loss: 0.0820\n",
            "Epoch 602/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0779\n",
            "Epoch 603/5981\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0826\n",
            "Epoch 604/5981\n",
            "3/3 [==============================] - 3s 920ms/step - loss: 0.0812\n",
            "Epoch 605/5981\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.0739\n",
            "Epoch 606/5981\n",
            "3/3 [==============================] - 1s 223ms/step - loss: 0.0784\n",
            "Epoch 607/5981\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.0762\n",
            "Epoch 608/5981\n",
            "3/3 [==============================] - 2s 586ms/step - loss: 0.0753\n",
            "Epoch 609/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0779\n",
            "Epoch 610/5981\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0801\n",
            "Epoch 611/5981\n",
            "3/3 [==============================] - 1s 428ms/step - loss: 0.0761\n",
            "Epoch 612/5981\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.0785\n",
            "Epoch 613/5981\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.0781\n",
            "Epoch 614/5981\n",
            "3/3 [==============================] - 2s 578ms/step - loss: 0.0784\n",
            "Epoch 615/5981\n",
            "3/3 [==============================] - 2s 662ms/step - loss: 0.0763\n",
            "Epoch 616/5981\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.0770\n",
            "Epoch 617/5981\n",
            "3/3 [==============================] - 2s 522ms/step - loss: 0.0823\n",
            "Epoch 618/5981\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0772"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SaveV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m         tld.op_callbacks, prefix, tensor_names, shape_and_slices, tensors)\n\u001b[0m\u001b[1;32m   1703\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f020b847cb57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5981\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[1;32m   1165\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[1;32m   1166\u001b[0m             % (optimizer,))\n\u001b[0;32m-> 1167\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m       \u001b[0;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1187\u001b[0;31m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[1;32m   1188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1134\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         return save_v2_eager_fallback(\n\u001b[1;32m   1707\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m   1709\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1728\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1730\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1731\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: training_checkpoints/ckpt_618_temp_05b66f93b38a4003b1c2723ae63a76ad/part-00001-of-00002.data-00000-of-00001.tempstate3369037823079991158; No space left on device [Op:SaveV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fETlS84xp_e3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQkN9rcVp_jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zrvPGXJp_or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvwNBIn4p_sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6M683kAp_yF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esik5askp_09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czoaEAzAp_3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjl8OJK1p_59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA629ooBp_8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZF-oz-Jp__D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWaVXXjRj8C8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYBkzqJqj8Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tA0Rqxvj8Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SqNfzOflXbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 100\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "    \n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8BuPhz9lXeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40aOlD4BlXhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh_LZ1o-lXjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXk6ijnXj8LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ2j_pFij8Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb_jo70_j8QV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iqxEtgGj8S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAbV6oU9j8Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnomQIEFj8YB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRrZYcC5j8ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTSgo5cBj8dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE4cWoDrj8fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YIwDHz5j8iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuLzvAz5j8kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dibrVIdYj8nD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2pJaK0_j8pZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scmIU_Hsj8r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK2ZVZQuj8uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZUI9ZM9j8wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0d7hzqPj8zD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCvYEweMj81h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVcxn6Zpj832",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNqCW6Ocj86K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoo4RJjZj88p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qKRTEWj8-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjWFbszEj9BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiRg3RZzj9Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5S5ouIjj9Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMusPP2j9IO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhkfoHRCj9Kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYWNdTNgj9Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMar4bfmj9O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGXnjvEpj9Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HJL4F2Fj9Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ztQoDgFj9VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2vR6qtpj9Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}