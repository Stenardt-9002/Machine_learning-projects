{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradientboostedtree.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP5Y2oBlvJx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q statsmodels\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULGyQUA-vOqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOXo-PRNvPEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-fZlZrRvPAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(123)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_UrH8k3vO-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc = tf.feature_column\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
        "                       'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fVT8Ll8vO7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc = tf.feature_column\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
        "                       'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n",
        "\n",
        "def one_hot_cat_column(feature_name, vocab):\n",
        "  return fc.indicator_column(\n",
        "      fc.categorical_column_with_vocabulary_list(feature_name,\n",
        "                                                 vocab))\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  # Need to one-hot encode categorical features.\n",
        "  vocabulary = dftrain[feature_name].unique()\n",
        "  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(fc.numeric_column(feature_name,\n",
        "                                           dtype=tf.float32))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ItwSY9vO45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use entire batch since this is such a small dataset.\n",
        "NUM_EXAMPLES = len(y_train)\n",
        "\n",
        "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
        "  def input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X.to_dict(orient='list'), y))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(NUM_EXAMPLES)\n",
        "    # For training, cycle thru dataset as many times as need (n_epochs=None).\n",
        "    dataset = (dataset\n",
        "      .repeat(n_epochs)\n",
        "      .batch(NUM_EXAMPLES))\n",
        "    return dataset\n",
        "  return input_fn\n",
        "\n",
        "# Training and evaluation input functions.\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FF49QaKvO2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIE5Es0jvOzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "c3054bb9-332b-4ff6-d091-57e91ae03058"
      },
      "source": [
        "params = {\n",
        "  'n_trees': 50,\n",
        "  'max_depth': 3,\n",
        "  'n_batches_per_layer': 1,\n",
        "  # You must enable center_bias = True to get DFCs. This will force the model to\n",
        "  # make an initial prediction before using any features (e.g. use the mean of\n",
        "  # the training labels for regression or log odds for classification when\n",
        "  # using cross entropy loss).\n",
        "  'center_bias': True\n",
        "}\n",
        "\n",
        "est = tf.estimator.BoostedTreesClassifier(feature_columns, **params)\n",
        "# Train model.\n",
        "est.train(train_input_fn, max_steps=1000)\n",
        "\n",
        "# Evaluation.\n",
        "results = est.evaluate(eval_input_fn)\n",
        "clear_output()\n",
        "pd.Series(results).to_frame()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.814394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy_baseline</th>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auc</th>\n",
              "      <td>0.869115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>auc_precision_recall</th>\n",
              "      <td>0.852467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_loss</th>\n",
              "      <td>0.414836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label/mean</th>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loss</th>\n",
              "      <td>0.414836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.760417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prediction/mean</th>\n",
              "      <td>0.388145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.737374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>global_step</th>\n",
              "      <td>153.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               0\n",
              "accuracy                0.814394\n",
              "accuracy_baseline       0.625000\n",
              "auc                     0.869115\n",
              "auc_precision_recall    0.852467\n",
              "average_loss            0.414836\n",
              "label/mean              0.375000\n",
              "loss                    0.414836\n",
              "precision               0.760417\n",
              "prediction/mean         0.388145\n",
              "recall                  0.737374\n",
              "global_step           153.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF_DMLgNvOvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuyBLwydvOm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnjddizhvOjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_881JO-QvOg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}